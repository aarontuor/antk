<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>All in One Tutorial via Matrix Factorization &mdash; antk 0.3.0 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="antk 0.3.0 documentation" href="index.html" />
    <link rel="up" title="Tutorials" href="tutorials.html" />
    <link rel="next" title="Command Line Scripts" href="command_line.html" />
    <link rel="prev" title="Generic Model Tutorial" href="generic_model_tutorial.html" /> 
  </head>
  <body role="document">

<div style="background-color: white; text-align: center; padding: 10px 10px 15px 15px">
<a href="index.html"><img src="_static/antlogo.png" border="0" alt="ant logo"/></a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="command_line.html" title="Command Line Scripts"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="generic_model_tutorial.html" title="Generic Model Tutorial"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>

          <li class="nav-item nav-item-1"><a href="tutorials.html" accesskey="U">Tutorials</a> &raquo;</li> 
      </ul>
    </div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">All in One Tutorial via Matrix Factorization</a><ul>
<li><a class="reference internal" href="#part-1-matrix-factorization-model">Part 1: Matrix Factorization Model</a></li>
<li><a class="reference internal" href="#part-2-tree-model">Part 2: Tree Model</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="generic_model_tutorial.html"
                        title="previous chapter">Generic Model Tutorial</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="command_line.html"
                        title="next chapter">Command Line Scripts</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/mf_tutorial.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="all-in-one-tutorial-via-matrix-factorization">
<h1>All in One Tutorial via Matrix Factorization<a class="headerlink" href="#all-in-one-tutorial-via-matrix-factorization" title="Permalink to this headline">¶</a></h1>
<p>Part 1 starts off with a somewhat gentle introduction to the toolkit by implementing basic matrix factorization ratings
prediction on the MovieLens 100k dataset. Read the directions carefully and be prepared
use your copy and pasting skills. Part 2 explores developing a more complex model using deep neural nets to incorporated
user and item meta data into the model.
Carefully reading parts 1 and 2 will pay off when you engage in the task of building a new model.</p>
<div class="section" id="part-1-matrix-factorization-model">
<h2>Part 1: Matrix Factorization Model<a class="headerlink" href="#part-1-matrix-factorization-model" title="Permalink to this headline">¶</a></h2>
<p>Low Rank Matrix Factorization is a popular machine learning technique used to produce recommendations
given a set of ratings a user has given an item. The known ratings are collected in a user-item utility matrix
and the missing entries are predicted by optimizing a low rank factorization of the utility matrix given the known
entries. The basic idea behind matrix factorization models is that the information encoded for items
in the columns of the utility matrix, and for users in the rows of the utility matrix is not
exactly independent. We optimize the objective function <span class="math">\(\sum_{(u,i)} (R_{ui} - P_i^T U_u)^2\)</span> over the observed
ratings for user <em>u</em> and item <em>i</em> using gradient descent.</p>
<img alt="_images/factormodel.png" class="align-center" src="_images/factormodel.png" />
<p>We can express the same optimization in the form of a computational graph that will play nicely with tensorflow:</p>
<img alt="_images/graphmf.png" class="align-center" src="_images/graphmf.png" />
<p>Here <span class="math">\(xitem_i\)</span>, and <span class="math">\(xuser_j\)</span> are some representation of the indices for the user and item vectors in the utility matrix.
These could be one hot vectors, which can then be matrix multiplied by the <em>P</em> and <em>U</em> matrices to select the corresponding
user and item vectors. In practice it is much faster to let <span class="math">\(xitem_i\)</span>, and <span class="math">\(xuser_j\)</span> be vectors of indices
which can be used by tensorflow&#8217;s <strong>gather</strong> or <strong>embedding_lookup</strong> functions to select the corresponding vector from
the <em>P</em> and <em>U</em> matrices.</p>
<p>This simple model isn&#8217;t difficult to code directly in tensorflow, but it&#8217;s simplicity allows a
demonstration of the functionality of the toolkit without having to tackle a more complex model.</p>
<p>We have some processed MovieLens 100k data prepared for this tutorial located at <a class="reference external" href="http://sw.cs.wwu.edu/~tuora/aarontuor/ml100k.tar.gz">http://sw.cs.wwu.edu/~tuora/aarontuor/ml100k.tar.gz</a> .
The original MovieLens 100k dataset is located at <a class="reference external" href="http://grouplens.org/datasets/movielens/">http://grouplens.org/datasets/movielens/</a> .</p>
<dl class="docutils">
<dt>To start let&#8217;s import the modules we need, retrieve our prepared data,</dt>
<dd>and use the <a class="reference internal" href="loader.html"><em>loader</em></a> module&#8217;s <a class="reference internal" href="loader.html#loader.read_data_sets" title="loader.read_data_sets"><code class="xref any py py-func docutils literal"><span class="pre">read_data_sets</span></code></a> function to load our data:</dd>
</dl>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">antk.core</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">antk.core</span> <span class="kn">import</span> <span class="n">generic_model</span>
<span class="kn">from</span> <span class="nn">antk.core</span> <span class="kn">import</span> <span class="n">loader</span>


<span class="n">loader</span><span class="o">.</span><span class="n">maybe_download</span><span class="p">(</span><span class="s1">&#39;ml100k.tar.gz&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;http://sw.cs.wwu.edu/~tuora/aarontuor/ml100k.tar.gz&#39;</span><span class="p">)</span>
<span class="n">loader</span><span class="o">.</span><span class="n">untar</span><span class="p">(</span><span class="s1">&#39;ml100k.tar.gz&#39;</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s1">&#39;ml100k&#39;</span><span class="p">,</span> <span class="n">folders</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;dev&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">],</span>
                              <span class="n">hashlist</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;item&#39;</span><span class="p">,</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;ratings&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>There is a lot more data in the ml100k folder than we need for demonstrating a basic MF model so we use the <strong>hashlist</strong> and
<strong>folders</strong> arguments to select only the data files we want.
We can view the dimensions types, and dictionary keys of the data we&#8217;ve loaded using the <a class="reference internal" href="loader.html#loader.DataSets.show" title="loader.DataSets.show"><code class="xref any py py-meth docutils literal"><span class="pre">DataSets.show</span></code></a> method,
which is a useful feature for debugging.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>The previous command will display this to the terminal:</p>
<img alt="_images/datatest.png" class="align-center" src="_images/datatest.png" />
<p>For this data there are 10,000 ratings in dev and test, and 80,000 ratings in train.
Notice that the data type of <em>item</em> and <em>user</em> above is <a class="reference internal" href="loader.html#loader.HotIndex" title="loader.HotIndex"><code class="xref any py py-class docutils literal"><span class="pre">HotIndex</span></code></a>. This is a data structure for storing
one hot vectors, with a field for a vector of indices into a one hot matrix and the column size of the one hot matrix.
This will be important as we intend to use the <a class="reference internal" href="node_ops.html#node_ops.lookup" title="node_ops.lookup"><code class="xref any py py-func docutils literal"><span class="pre">lookup</span></code></a> function, which takes <a class="reference internal" href="loader.html#loader.HotIndex" title="loader.HotIndex"><code class="xref any py py-class docutils literal"><span class="pre">HotIndex</span></code></a>
objects for its <em>data</em> argument, makes a placeholder associated with this data and uses the <a class="reference internal" href="loader.html#loader.HotIndex.dim" title="loader.HotIndex.dim"><code class="xref any py py-attr docutils literal"><span class="pre">dim</span></code></a> attribute of the <a class="reference internal" href="loader.html#loader.HotIndex" title="loader.HotIndex"><code class="xref any py py-class docutils literal"><span class="pre">HotIndex</span></code></a>
data to create a <strong>tf.Variable</strong> tensor with the correct dimension. The output is an <strong>embedding_lookup</strong> using the placeholder
and variable tensors created.</p>
<p>This model does better with the target ratings centered about the mean so let&#8217;s center the ratings.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="s1">&#39;ratings&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="s1">&#39;ratings&#39;</span><span class="p">])</span>
<span class="n">data</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="s1">&#39;ratings&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="s1">&#39;ratings&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="admonition-todo admonition" id="index-0">
<p class="first admonition-title">Todo</p>
<p class="last">Make a plain text file named mf.config using the text below. We will use this to make the tensorflow computational graph:</p>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">dotproduct</span> <span class="n">x_dot_y</span><span class="p">()</span>
    <span class="o">-</span><span class="n">huser</span> <span class="n">lookup</span><span class="p">(</span><span class="n">dataname</span><span class="o">=</span><span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="n">initrange</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
    <span class="o">-</span><span class="n">hitem</span> <span class="n">lookup</span><span class="p">(</span><span class="n">dataname</span><span class="o">=</span><span class="s1">&#39;item&#39;</span><span class="p">,</span> <span class="n">initrange</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
    <span class="o">-</span><span class="n">ibias</span> <span class="n">lookup</span><span class="p">(</span><span class="n">dataname</span><span class="o">=</span><span class="s1">&#39;item&#39;</span><span class="p">,</span> <span class="n">initrange</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="o">-</span><span class="n">ubias</span> <span class="n">lookup</span><span class="p">(</span><span class="n">dataname</span><span class="o">=</span><span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="n">initrange</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>The python syntax highlighting illustrates the fact that
the node specifications in a .config file are just python function calls with two things omitted, the first argument
which is a tensor or list of tensors, and the last argument which is the name of the tensor output which defines it&#8217;s unique
variable scope. The first argument is derived from the structure of the config spec, inferred by a marker symbol which we have
chosen as &#8216;-&#8216;. The input is
the list of tensors or the single tensor in the spec at the next level below a node call. Tabbing is optional. It may be easier to read
a config file with tabbing if you are using node functions without a long sequence of arguments.
The second omitted argument, the name, is whatever directly follows the graph markers.</p>
<p>Now we make an <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> object.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;mfgraph&#39;</span><span class="p">):</span>
<span class="n">ant</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">AntGraph</span><span class="p">(</span><span class="s1">&#39;mf.config&#39;</span><span class="p">,</span>
                        <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">features</span><span class="p">,</span>
                        <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span>
                        <span class="n">develop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>When you run the code now you will get a complete print of the tensors made from the config file because we have set the
<strong>develop</strong> argument to <strong>True</strong>.</p>
<img alt="_images/tensor_print.png" src="_images/tensor_print.png" />
<p>We can get a visual representation of the graph with another line:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">ant</span><span class="o">.</span><span class="n">display_graph</span><span class="p">()</span>
</pre></div>
</div>
<p>When you run this code a graphviz dot pdf image of the graph you have composed should pop up on the screen (assuming you
have graphviz installed). This pdf file will show up in the pics folder with the name <strong>no_name.pdf</strong>. There are of course
parameters for specifying the name and location where you want the picture to go. The dot specification will be located
in the same place as the picture and be named <strong>no_name.dot</strong> unless you have specified a name for the file.</p>
<img alt="_images/no_name.png" class="align-center" src="_images/no_name.png" />
<p>Shown in the graph picture above the <a class="reference internal" href="node_ops.html#node_ops.x_dot_y" title="node_ops.x_dot_y"><code class="xref any py py-func docutils literal"><span class="pre">x_dot_y</span></code></a> function takes a list of tensors as its first argument.
The first two tensors are matrices whose rows are dot producted resulting in a vector containing a scalar for each row.
The second two tensors are optional biases. For this model, giving a user and item bias helps a great deal. When <a class="reference internal" href="node_ops.html#node_ops.lookup" title="node_ops.lookup"><code class="xref any py py-func docutils literal"><span class="pre">lookup</span></code></a>
is called more than once in a config file using the same <em>data</em> argument the previously made placeholder tensor is used,
so here <em>ibias</em> depends on the same placeholder as <em>hbias</em> and <em>ubias</em> depends on the same placeholder as <em>huser</em>, which
is what we want.</p>
<p>The <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> object, <em>ant</em> is a complete record of the tensors created in graph building.
There are three accessible fields, <a class="reference internal" href="config.html#config.AntGraph.tensordict" title="config.AntGraph.tensordict"><code class="xref any py py-attr docutils literal"><span class="pre">tensordict</span></code></a>, <a class="reference internal" href="config.html#config.AntGraph.placeholderdict" title="config.AntGraph.placeholderdict"><code class="xref any py py-attr docutils literal"><span class="pre">placeholderdict</span></code></a>, and <a class="reference internal" href="config.html#config.AntGraph.tensor_out" title="config.AntGraph.tensor_out"><code class="xref any py py-attr docutils literal"><span class="pre">tensor_out</span></code></a>,
which are a dictionary of non-placeholder tensors made during graph creation, a dictionary of placeholder tensors made during
graph creation and the tensor or list of tensors which is the output of the top level node function.
These should be useful if we want to access tensors post graph creation.</p>
<p>Okay let&#8217;s finish making this model:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">ant</span><span class="o">.</span><span class="n">tensor_out</span>
<span class="n">y_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Target&#39;</span><span class="p">)</span>
<span class="n">ant</span><span class="o">.</span><span class="n">placeholderdict</span><span class="p">[</span><span class="s1">&#39;ratings&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_</span> <span class="c1"># put the new placeholder in the placeholderdict for training</span>
<span class="n">objective</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y_</span> <span class="o">-</span> <span class="n">y</span><span class="p">))</span> <span class="o">+</span>
             <span class="mf">0.1</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">ant</span><span class="o">.</span><span class="n">tensordict</span><span class="p">[</span><span class="s1">&#39;huser&#39;</span><span class="p">]))</span> <span class="o">+</span>
             <span class="mf">0.1</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">ant</span><span class="o">.</span><span class="n">tensordict</span><span class="p">[</span><span class="s1">&#39;hitem&#39;</span><span class="p">]))</span> <span class="o">+</span>
             <span class="mf">0.1</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">ant</span><span class="o">.</span><span class="n">tensordict</span><span class="p">[</span><span class="s1">&#39;ubias&#39;</span><span class="p">]))</span> <span class="o">+</span>
             <span class="mf">0.1</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">ant</span><span class="o">.</span><span class="n">tensordict</span><span class="p">[</span><span class="s1">&#39;ibias&#39;</span><span class="p">])))</span>
<span class="n">dev_rmse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_</span><span class="p">)),</span> <span class="n">data</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">num_examples</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">generic_model</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">ant</span><span class="o">.</span><span class="n">placeholderdict</span><span class="p">,</span>
          <span class="n">mb</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
          <span class="n">learnrate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
          <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
          <span class="n">maxbadcount</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">evaluate</span><span class="o">=</span><span class="n">dev_rmse</span><span class="p">,</span>
          <span class="n">predictions</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>Notice that the <a class="reference internal" href="config.html#config.AntGraph.tensordict" title="config.AntGraph.tensordict"><code class="xref any py py-attr docutils literal"><span class="pre">tensordict</span></code></a> enables easy access to <em>huser</em>, <em>hitem</em>, <em>ubias</em>, <em>ibias</em>, which we want to regularize to
prevent overfitting. The <a class="reference internal" href="generic_model.html#generic_model.Model" title="generic_model.Model"><code class="xref any py py-class docutils literal"><span class="pre">Model</span></code></a> object we are creating <em>model</em> needs the fields <em>objective</em>, <em>placeholderdict</em>, <em>predictions</em>, and <em>targets</em>.
If you don&#8217;t specify the other parameters default values are set. <em>objective</em> is used as the loss function for gradient
descent. <em>placeholderdict</em> is used to pair placeholder tensors with matrices from a dataset dictionary with the same
keys. <em>targets</em>, and <em>predictions</em> are employed by the loss function during evaluation, and by the prediction function
to give outputs from a trained model.</p>
<p>Training is now as easy as:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">dev</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dev</span><span class="p">)</span>
</pre></div>
</div>
<p>You should get about 0.92 RMSE.</p>
<p>There are a few antk functionalities we can take advantage of to make our code more compact. Any node_op function that
creates trainable weights has a parameter for adding l2 regularization to the weights of the model. We just change
our config as below and we can eliminate the four extra lines in the definition of <strong>objective</strong>.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">dotproduct</span> <span class="n">x_dot_y</span><span class="p">()</span>
    <span class="o">-</span><span class="n">huser</span> <span class="n">lookup</span><span class="p">(</span><span class="n">dataname</span><span class="o">=</span><span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="n">initrange</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
    <span class="o">-</span><span class="n">hitem</span> <span class="n">lookup</span><span class="p">(</span><span class="n">dataname</span><span class="o">=</span><span class="s1">&#39;item&#39;</span><span class="p">,</span> <span class="n">initrange</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
    <span class="o">-</span><span class="n">ibias</span> <span class="n">lookup</span><span class="p">(</span><span class="n">dataname</span><span class="o">=</span><span class="s1">&#39;item&#39;</span><span class="p">,</span> <span class="n">initrange</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="o">-</span><span class="n">ubias</span> <span class="n">lookup</span><span class="p">(</span><span class="n">dataname</span><span class="o">=</span><span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="n">initrange</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>Also, we have a function for RMSE, and we can evaluate the mean absolute error using
the <strong>save_tensors</strong> argument to the <a class="reference internal" href="generic_model.html"><em>generic_model</em></a> constructor. Our code now looks like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">ant</span><span class="o">.</span><span class="n">tensor_out</span>
<span class="n">y_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Target&#39;</span><span class="p">)</span>
<span class="n">ant</span><span class="o">.</span><span class="n">placeholderdict</span><span class="p">[</span><span class="s1">&#39;ratings&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_</span> <span class="c1"># put the new placeholder in the graph for training</span>
<span class="n">objective</span> <span class="o">=</span> <span class="n">node_ops</span><span class="o">.</span><span class="n">se</span><span class="p">(</span><span class="n">y_</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
<span class="n">dev_rmse</span> <span class="o">=</span>  <span class="n">node_ops</span><span class="o">.</span><span class="n">rmse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_</span><span class="p">)</span>
<span class="n">dev_mae</span> <span class="o">=</span> <span class="n">node_ops</span><span class="o">.</span><span class="n">mae</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">generic_model</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">ant</span><span class="o">.</span><span class="n">placeholderdict</span><span class="p">,</span>
          <span class="n">mb</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
          <span class="n">learnrate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
          <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
          <span class="n">maxbadcount</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">evaluate</span><span class="o">=</span><span class="n">dev_rmse</span><span class="p">,</span>
          <span class="n">predictions</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
          <span class="n">save_tensors</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;dev_mae&#39;</span><span class="p">:</span> <span class="n">dev_mae</span><span class="p">})</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">dev</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dev</span><span class="p">)</span>
</pre></div>
</div>
<p>If you don&#8217;t wan&#8217;t to evaluate a model during training, for instance if you are doing cross-validation, you can just hand the <a class="reference internal" href="generic_model.html#generic_model.Model.train" title="generic_model.Model.train"><code class="xref any py py-meth docutils literal"><span class="pre">train</span></code></a>
method a training set and omit the dev set. Note that here there must be keys in either the <a class="reference internal" href="loader.html#loader.DataSet" title="loader.DataSet"><code class="xref any py py-class docutils literal"><span class="pre">DataSet</span></code></a>
<a class="reference internal" href="loader.html#loader.DataSet.features" title="loader.DataSet.features"><code class="xref any py py-attr docutils literal"><span class="pre">features</span></code></a>, or <a class="reference internal" href="loader.html#loader.DataSet.labels" title="loader.DataSet.labels"><code class="xref any py py-attr docutils literal"><span class="pre">labels</span></code></a> dictionaries, that match with the keys from the <a class="reference internal" href="config.html#config.AntGraph.placeholderdict" title="config.AntGraph.placeholderdict"><code class="xref any py py-attr docutils literal"><span class="pre">placeholderdict</span></code></a> which is handed
to the <a class="reference internal" href="generic_model.html#generic_model.Model" title="generic_model.Model"><code class="xref any py py-class docutils literal"><span class="pre">Model</span></code></a> constructor. In our case we have placed a placeholder with the key <em>ratings</em> in the
<code class="xref any docutils literal"><span class="pre">placeholdedict</span></code> corresponding to
the <em>ratings</em> key in our <em>data</em> <a class="reference internal" href="loader.html#loader.DataSet" title="loader.DataSet"><code class="xref any py py-class docutils literal"><span class="pre">DataSet</span></code></a>. So our <a class="reference internal" href="config.html#config.AntGraph.placeholderdict" title="config.AntGraph.placeholderdict"><code class="xref any py py-attr docutils literal"><span class="pre">placeholderdict</span></code></a> is:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;item&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7f0bea7b43d0</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="s1">&#39;user&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7f0bea846e90</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="s1">&#39;ratings&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7f0bea77fc90</span><span class="o">&gt;</span><span class="p">}</span>
</pre></div>
</div>
<p>Now we have a trained model that does pretty well but it would be nice to automate a hyper-parameter search to find the best
we can do (should be around .91).</p>
<p>We can change our mf.config file to accept variables for hyperparameters by substituting hard values with variable names
prefixed with a &#8216;$&#8217;:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>dotproduct x_dot_y()
     -huser lookup(dataname=&#39;user&#39;, initrange=$initrange, l2=$l2, shape=[None, $kfactors])
     -hitem lookup(dataname=&#39;item&#39;, initrange=$initrange, l2=$l2, shape=[None, $kfactors])
     -ibias lookup(dataname=&#39;item&#39;, initrange=$initrange, l2=$l2, shape=[None, 1])
     -ubias lookup(dataname=&#39;user&#39;, initrange=$initrange, l2=$l2, shape=[None, 1])
</pre></div>
</div>
<p>Now we have to let the <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> constructor know what to bind these variables to with a <em>variable_bindings</em>
argument. So change the constructor call like so.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;mfgraph&#39;</span><span class="p">):</span>
    <span class="n">ant</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">AntGraph</span><span class="p">(</span><span class="s1">&#39;mf.config&#39;</span><span class="p">,</span>
                            <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">features</span><span class="p">,</span>
                            <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span>
                            <span class="n">variable_bindings</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kfactors&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="s1">&#39;initrange&#39;</span><span class="p">:</span><span class="mf">0.001</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">:</span><span class="mf">0.1</span><span class="p">})</span>
</pre></div>
</div>
<div class="admonition-todo admonition" id="index-1">
<p class="first admonition-title">Todo</p>
<p class="last">Modify the code you&#8217;ve written to take command line arguments for the hyperparameters: <em>kfactors</em>, <em>initrange</em>, <em>mb</em>, <em>learnrate</em>, <em>maxbadcount</em>, <em>l2</em>,
and <em>epochs</em>, and conduct a parameter search for the best model.</p>
</div>
</div>
<div class="section" id="part-2-tree-model">
<h2>Part 2: Tree Model<a class="headerlink" href="#part-2-tree-model" title="Permalink to this headline">¶</a></h2>
<p>To demonstrate the power and flexibility of using a config file we can make this more complex model
below by changing a few lines of code and using a different config file:</p>
<img alt="_images/tree1.png" class="align-center" src="_images/tree1.png" />
<p>We need to change the <a class="reference internal" href="loader.html#loader.read_data_sets" title="loader.read_data_sets"><code class="xref any py py-func docutils literal"><span class="pre">read_data_sets</span></code></a> call to omit the optional <em>hashlist</em> parameter so we get more features from
the data folder (if a <em>hashlist</em> parameter is not supplied, <a class="reference internal" href="loader.html#loader.read_data_sets" title="loader.read_data_sets"><code class="xref any py py-func docutils literal"><span class="pre">read_data_sets</span></code></a> reads all files with name prefixes
<strong>features_</strong> and <strong>labels_</strong> ).</p>
<div class="admonition-todo admonition" id="index-2">
<p class="first admonition-title">Todo</p>
<p class="last">Make a new python file tree.py with the code below:</p>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">antk.core</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">antk.core</span> <span class="kn">import</span> <span class="n">generic_model</span>
<span class="kn">from</span> <span class="nn">antk.core</span> <span class="kn">import</span> <span class="n">loader</span>
<span class="kn">from</span> <span class="nn">antk.core</span> <span class="kn">import</span> <span class="n">node_ops</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s1">&#39;ml100k&#39;</span><span class="p">,</span> <span class="n">folders</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;dev&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;item&#39;</span><span class="p">,</span> <span class="s1">&#39;user&#39;</span><span class="p">])</span>
<span class="n">data</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Now we have some user and item meta data which we can examine:</p>
<img alt="_images/ml100kmore.png" src="_images/ml100kmore.png" />
<p>The idea of this model is to have a deep neural network for each stream of user meta data and item meta data. The user and item dnn&#8217;s are
concatenated respectively and then fed to a user dnn and an item dnn. The outputs of these dnn&#8217;s are dot producted to provide ratings predictions.
We can succinctly express this model in a .config file.</p>
<div class="admonition-todo admonition" id="index-3">
<p class="first admonition-title">Todo</p>
<p class="last">Make a plain text file called tree.config with the specs for our tree model.</p>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>dotproduct x_dot_y()
-all_user dnn([$kfactors,$kfactors,$kfactors], activation=&#39;tanh&#39;,bn=True,keep_prob=0.95)
--tanh_user tf.nn.tanh()
---merge_user concat($kfactors)
----huser lookup(dataname=&#39;user&#39;, initrange=$initrange, shape=[None, $kfactors])
----hage dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=0.95)
-----agelookup embedding()
------age placeholder(tf.float32)
------user placeholder(tf.int32)
----hsex dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=0.95)
-----sexlookup embedding()
------sex_weights weights(&#39;tnorm&#39;, [2, $kfactors])
------sexes embedding()
-------sex placeholder(tf.int32)
-------user placeholder(tf.int32)
----hocc dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=0.95)
-----occlookup embedding()
------occ_weights weights(&#39;tnorm&#39;, [21, $kfactors])
------occs embedding()
-------occ placeholder(tf.int32)
-------user placeholder(tf.int32)
----hzip dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=0.95)
-----ziplookup embedding()
------zip_weights weights(&#39;tnorm&#39;, [1000, $kfactors])
------zips embedding()
-------zip placeholder(tf.int32)
-------user placeholder(tf.int32)
----husertime dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=0.95)
-----time placeholder(tf.float32)
-all_item dnn([$kfactors,$kfactors,$kfactors], activation=&#39;tanh&#39;,bn=True,keep_prob=0.95)
--tanh_item tf.nn.tanh()
---merge_item concat($kfactors)
----hitem lookup(dataname=&#39;item&#39;, initrange=$initrange, shape=[None, $kfactors])
----hgenre dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=0.95)
-----genrelookup embedding()
------genres placeholder(tf.float32)
------item placeholder(tf.int32)
----hmonth dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=0.95)
-----monthlookup embedding()
------month_weights weights(&#39;tnorm&#39;, [12, $kfactors])
------months embedding()
-------month placeholder(tf.int32)
-------item placeholder(tf.int32)
----hyear dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=0.95)
-----yearlookup embedding()
------year placeholder(tf.float32)
------item placeholder(tf.int32)
----htfidf dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=0.95)
-----tfidflookup embedding()
------tfidf_doc_term placeholder(tf.float32)
------item placeholder(tf.int32)
----hitemtime dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=0.95)
-----time placeholder(tf.float32)
-ibias lookup(dataname=&#39;item&#39;, shape=[None, 1], initrange=$initrange)
-ubias lookup(dataname=&#39;user&#39;, shape=[None, 1], initrange=$initrange)
</pre></div>
</div>
<p>This model employs all the user and item meta-data we have at our disposal. The config file looks pretty complicated, and it is,
but at least it fits on a screen and we can <em>read</em> the high level structure of the model. Imagine developing this model with straight python tensorflow code. This would be hundreds of lines of code and it would be much more difficult to <em>see</em> what was going on with the model.
We can see what the model will look like without actually building the graph with the <a class="reference internal" href="config.html#config.testGraph" title="config.testGraph"><code class="xref any py py-func docutils literal"><span class="pre">config.testGraph</span></code></a> function.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">config</span><span class="o">.</span><span class="n">testGraph</span><span class="p">(</span><span class="s1">&#39;tree.config&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/tree_test.png" src="_images/tree_test.png" />
<p>This looks like a pretty cool model! We should probably normalize the meta data features for training though.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="s1">&#39;ratings&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="s1">&#39;ratings&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="s1">&#39;ratings&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="s1">&#39;ratings&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">maxnormalize</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">])</span>
<span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">maxnormalize</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>All our other features besides time are categorical and so use lookups. I think I normalized time during data processing but
it couldn&#8217;t hurt to check. If you think it is a good idea you can whiten these data inputs to have zero mean and unit variance
with some convenience functions from the <a class="reference internal" href="loader.html"><em>loader</em></a> module. Now we should build our graph. Notice that we have omitted the
l2 variable in the config file. We are using dropout to regularize our output as an alternative, since this is a standard regularization
technique for deep neural networks.</p>
<p>Remember we need a python dictionary of numpy matrices whose keys match the names of placeholder and lookup operations that will
infer dimensions for the <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> constructor. So we need to add these lines:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">datadict</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">datadict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
<span class="n">configdatadict</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">configdatadict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">datadict</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we can build the graph. We&#8217;ll set <strong>develop</strong> to <strong>False</strong> because a lot of tensors are going to get made. If something
goes wrong with a model this big set <strong>develop</strong> to <strong>True</strong> and pipe standard output to a file for analysis:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;mfgraph&#39;</span><span class="p">):</span>
    <span class="n">ant</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">AntGraph</span><span class="p">(</span><span class="s1">&#39;tree.config&#39;</span><span class="p">,</span>
                            <span class="n">data</span><span class="o">=</span><span class="n">configdatadict</span><span class="p">,</span>
                            <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span>
                            <span class="n">variable_bindings</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kfactors&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="s1">&#39;initrange&#39;</span><span class="p">:</span><span class="mf">0.001</span><span class="p">},</span>
                            <span class="n">develop</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">ant</span><span class="o">.</span><span class="n">tensor_out</span>
<span class="n">y_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Target&#39;</span><span class="p">)</span>
<span class="n">ant</span><span class="o">.</span><span class="n">placeholderdict</span><span class="p">[</span><span class="s1">&#39;ratings&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_</span>  <span class="c1"># put the new placeholder in the graph for training</span>
<span class="n">objective</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y_</span> <span class="o">-</span> <span class="n">y</span><span class="p">))</span>
<span class="n">dev_rmse</span> <span class="o">=</span>  <span class="n">node_ops</span><span class="o">.</span><span class="n">rmse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_</span><span class="p">)</span>
</pre></div>
</div>
<p>Training this model will naturally take longer so we can set the evaluation schedule to be shorter than an epoch to check
in on how things are doing. Also, we will need a smaller learnrate for gradient descent. So we can initialize a <a class="reference internal" href="generic_model.html#generic_model.Model" title="generic_model.Model"><code class="xref any py py-class docutils literal"><span class="pre">Model</span></code></a> object
with the following hyper-parameters as a first approximation, and then train away...</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">generic_model</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">ant</span><span class="o">.</span><span class="n">placeholderdict</span><span class="p">,</span>
                            <span class="n">mb</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                            <span class="n">learnrate</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span>
                            <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                            <span class="n">maxbadcount</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                            <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                            <span class="n">evaluate</span><span class="o">=</span><span class="n">dev_rmse</span><span class="p">,</span>
                            <span class="n">predictions</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">dev</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dev</span><span class="p">,</span> <span class="n">supplement</span><span class="o">=</span><span class="n">datadict</span><span class="p">,</span> <span class="n">eval_schedule</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">We added the supplement argument to <a class="reference internal" href="generic_model.html#generic_model.Model.train" title="generic_model.Model.train"><code class="xref any py py-meth docutils literal"><span class="pre">train</span></code></a> so that the placeholders related to meta-data could be added to the tensorflow
feed dictionary with the backend function <code class="xref any docutils literal"><span class="pre">get_feed_dict</span></code> employed by the <a class="reference internal" href="generic_model.html#generic_model.Model" title="generic_model.Model"><code class="xref any py py-class docutils literal"><span class="pre">Model</span></code></a> constructor.</p>
</div>
<p>This model takes a while to train and from some poking around it is hard to find a set of hyperparameters that will approach the
accuracy of a basic matrix factorization model. The hyperparameters I have provided should give about 0.93 RMSE which isn&#8217;t good for this data set.
We have a lot of things to try such as batch normalization, dropout, hidden layer size,
number of hidden layers, activation functions, optimization strategies, subsets of the meta data to incorporate into the mode, and of course the
standard learning rate and intitialization strategies.</p>
<div class="admonition-todo admonition" id="index-4">
<p class="first admonition-title">Todo</p>
<p class="last">Modify the code you&#8217;ve written to take arguments for the set of new hyperparameters, and optional optimization parameters
from the <a class="reference internal" href="generic_model.html#generic_model.Model" title="generic_model.Model"><code class="xref any py py-class docutils literal"><span class="pre">Model</span></code></a> API. Perform a parameter search to see if you can do better than basic MF.</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="command_line.html" title="Command Line Scripts"
             >next</a> |</li>
        <li class="right" >
          <a href="generic_model_tutorial.html" title="Generic Model Tutorial"
             >previous</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>

          <li class="nav-item nav-item-1"><a href="tutorials.html" >Tutorials</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2016, Aaron Tuor.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.6.
    </div>
  </body>
</html>