<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Part 3: Crafting a new model &mdash; antk 0.3.0 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="antk 0.3.0 documentation" href="index.html" /> 
  </head>
  <body role="document">

<div style="background-color: white; text-align: center; padding: 10px 10px 15px 15px">
<a href="index.html"><img src="_static/antlogo.png" border="0" alt="ant logo"/></a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>
 
      </ul>
    </div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/model_crafting.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="part-3-crafting-a-new-model">
<h1>Part 3: Crafting a new model<a class="headerlink" href="#part-3-crafting-a-new-model" title="Permalink to this headline">Â¶</a></h1>
<p>So far we have been using functions in our config files that are defined in the <a class="reference internal" href="node_ops.html"><span class="doc">node_ops</span></a> module. In the model we
have defined, the <strong>concat</strong> nodes are passed directly to <strong>dnn</strong> nodes with no intervening non-linearity. We can introduce
non-linear transformations at these points by directly calling tensorflow non-linear transforms in the config file.</p>
<div class="admonition-todo admonition" id="index-0">
<p class="first admonition-title">Todo</p>
<p class="last">Introduce tensorflow non-linear transforms in tree.config</p>
</div>
<p>We also have the ablility to introduce new node functions which are not defined by tensorflow or <a class="reference internal" href="node_ops.html"><span class="doc">node_ops</span></a>.
One thing we might try is to replace our <strong>dnn</strong> nodes with <strong>highway_dnn</strong> nodes that we need to define. Here is a first
approximation of defining a new <strong>highway_dnn</strong> node:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">node_ops</span>

<span class="k">def</span> <span class="nf">highway_dnn</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">keep_prob</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;highway_dnn&#39;</span><span class="p">):</span>
    <span class="n">activation</span> <span class="o">=</span> <span class="n">node_ops</span><span class="o">.</span><span class="n">ACTIVATION</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n_units</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;layer</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">):</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;hidden&#39;</span><span class="p">):</span>
                    <span class="n">hidden</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">node_ops</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="n">n_units</span><span class="p">,</span> <span class="bp">True</span><span class="p">))</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;transform&#39;</span><span class="p">):</span>
                    <span class="n">transform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">node_ops</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="n">n_units</span><span class="p">,</span> <span class="bp">True</span><span class="p">))</span>
                <span class="n">tensor_in</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">transform</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">keep_prob</span><span class="p">:</span>
                    <span class="n">tensor_in</span> <span class="o">=</span> <span class="n">node_ops</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensor_in</span>
</pre></div>
</div>
<p>This looks okay for a first approximation. However we would like to initialize the bias for the transform gate to some
negative value, so we have to set the optional <em>bias_start=0</em> parameter in the call to <a class="reference internal" href="node_ops.html#node_ops.linear" title="node_ops.linear"><code class="xref any py py-func docutils literal"><span class="pre">linear</span></code></a> for the transform gate to
a value we would like.</p>
<div class="admonition-todo admonition" id="index-1">
<p class="first admonition-title">Todo</p>
<p class="last">Alter the <strong>highway_dnn</strong> code to take an optional parameter for transform bias initialization. Replace <strong>dnn</strong> nodes
in tree.config with <strong>highway_dnn</strong> nodes.</p>
</div>
<p>Now we need to let the <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> constructor know about our new node by using the factory constructor <code class="xref any docutils literal"><span class="pre">graph_setup</span></code> with
one of the two optional arguments introducing new node functions. If
your new node definition is in it&#8217;s own module possibly full of other node definitions you have created you can use the
<em>imports</em> argument which is a dictionary with module names as keys and the paths to modules as values. In our case since we
have only made one new node function we will use the <em>function_map</em> parameter which takes a dictionary of function_name keys
and function values. So we replace our <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> constructor call as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;mfgraph&#39;</span><span class="p">):</span>
    <span class="n">ant</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_setup</span><span class="p">(</span><span class="s1">&#39;tree.config&#39;</span><span class="p">,</span>
                              <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">-</span><span class="n">dev</span><span class="p">,</span>
                              <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span>
                              <span class="n">function_map</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;highway_dnn&#39;</span><span class="p">:</span> <span class="n">highway_dnn</span><span class="p">},</span>
                              <span class="n">variable_bindings</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kfactors&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s1">&#39;initrange&#39;</span><span class="p">:</span><span class="mf">0.001</span><span class="p">})</span>
</pre></div>
</div>
<p>Here is an example config file and corresponding graphviz dot image adding non-linearity and a <strong>highway_dnn</strong> node.
Notice that since highway networks have a fixed dimension size for hidden layers we have used an intermediate <strong>dnn</strong> node
to map the input to a dimension we want.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>dotproduct x_dot_y()
-all_user dnn([$kfactors,$kfactors,$kfactors], activation=&#39;tanh&#39;,bn=True,keep_prob=None)
--tanh_user tf.nn.tanh()
---merge_user concat($kfactors)
----huser lookup(dataname=&#39;user&#39;, initrange=$initrange, shape=[None, $kfactors])
----hage dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----agelookup embedding()
------age placeholder(tf.float32)
------user placeholder(tf.int32)
----hsex dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----sexlookup embedding()
------sex_weights weights(&#39;tnorm&#39;, tf.float32, [2, $kfactors])
------sexes embedding()
-------sex placeholder(tf.int32)
-------user placeholder(tf.int32)
----hocc dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----occlookup embedding()
------occ_weights weights(&#39;tnorm&#39;, tf.float32, [21, $kfactors])
------occs embedding()
-------occ placeholder(tf.int32)
-------user placeholder(tf.int32)
----hzip dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----ziplookup embedding()
------zip_weights weights(&#39;tnorm&#39;, tf.float32, [1000, $kfactors])
------zips embedding()
-------zip placeholder(tf.int32)
-------user placeholder(tf.int32)
----husertime dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----time placeholder(tf.float32)
-all_item dnn([$kfactors,$kfactors,$kfactors], activation=&#39;tanh&#39;,bn=True,keep_prob=None)
--tanh_item tf.nn.tanh()
---merge_item concat($kfactors)
----hitem lookup(dataname=&#39;item&#39;, initrange=$initrange, shape=[None, $kfactors])
----hgenre dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----genrelookup embedding()
------genres placeholder(tf.float32)
------item placeholder(tf.int32)
----hmonth dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----monthlookup embedding()
------month_weights weights(&#39;tnorm&#39;, tf.float32, [12, $kfactors])
------months embedding()
-------month placeholder(tf.int32)
-------item placeholder(tf.int32)
----hyear dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----yearlookup embedding()
------year placeholder(tf.float32)
------item placeholder(tf.int32)
----htfidf dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----tfidflookup embedding()
------tfidf_doc_term placeholder(tf.float32)
------item placeholder(tf.int32)
----hitemtime dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----time placeholder(tf.float32)
-ibias lookup(dataname=&#39;item&#39;, shape=[None, 1], initrange=$initrange)
-ubias lookup(dataname=&#39;user&#39;, shape=[None, 1], initrange=$initrange)
</pre></div>
</div>
<img alt="_images/highway_nonlinear.png" class="align-center" src="_images/highway_nonlinear.png" />
<p>Now that we are familiar with the tricks for crafting new models we can engage in creative enterprise. We have been using
the scalar ratings targets for objectives, but there are also one hot targets for classification included in the dataset.</p>
<div class="admonition-todo admonition" id="index-2">
<p class="first admonition-title">Todo</p>
<p>Using the data provided, craft your own model, and do some preliminary testing to see how it performs against
the other models you have explored. If you run into a bug, contact me and I will try to address it but feel free
to just take note of the bug, abandon the effort, and try something else.
Some ideas:</p>
<blockquote>
<div><p>Classification</p>
<p>Multiple targets of regression and classification</p>
<p>A different combine function which has a multiplicative interaction between data streams</p>
<p>Combining data streams in a binary fashion (for item streams don&#8217;t combine all three at once)</p>
<p>Scale the regression targets and use the built in <a class="reference internal" href="node_ops.html#node_ops.cosine" title="node_ops.cosine"><code class="xref any py py-func docutils literal"><span class="pre">cosine</span></code></a> node function instead of <a class="reference internal" href="node_ops.html#node_ops.x_dot_y" title="node_ops.x_dot_y"><code class="xref any py py-func docutils literal"><span class="pre">x_dot_y</span></code></a></p>
<p>Make the branches dealing with indices linear, as they are in basic MF, and combine them later in the tree</p>
<p>Create an LSTM node that takes a sequence as input and outputs the last hidden state vector.</p>
</div></blockquote>
<p class="last">For this task results are not paramount. Think of a way to address the data that makes sense and explores the kind of
functionality you may want to employ the toolkit for.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>
 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2016, Aaron Tuor.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.4.5.
    </div>
  </body>
</html>