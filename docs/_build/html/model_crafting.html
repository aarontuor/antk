

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Part 3: Crafting a new model &mdash; antk 1.0 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="antk 1.0 documentation" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> antk
          

          
            
            <img src="_static/antlogo_cut_shrunk2.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="api.html">API: ANT modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="command_line.html">Command Line Scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="command_line.html#movie-lens-processing">Movie Lens Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Models</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">antk</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Part 3: Crafting a new model</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/model_crafting.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="part-3-crafting-a-new-model">
<h1>Part 3: Crafting a new model<a class="headerlink" href="#part-3-crafting-a-new-model" title="Permalink to this headline">Â¶</a></h1>
<p>So far we have been using functions in our config files that are defined in the <a class="reference internal" href="node_ops.html"><em>node_ops</em></a> module. In the model we
have defined, the <strong>concat</strong> nodes are passed directly to <strong>dnn</strong> nodes with no intervening non-linearity. We can introduce
non-linear transformations at these points by directly calling tensorflow non-linear transforms in the config file.</p>
<div class="admonition-todo admonition" id="index-0">
<p class="first admonition-title">Todo</p>
<p class="last">Introduce tensorflow non-linear transforms in tree.config</p>
</div>
<p>We also have the ablility to introduce new node functions which are not defined by tensorflow or <a class="reference internal" href="node_ops.html"><em>node_ops</em></a>.
One thing we might try is to replace our <strong>dnn</strong> nodes with <strong>highway_dnn</strong> nodes that we need to define. Here is a first
approximation of defining a new <strong>highway_dnn</strong> node:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">node_ops</span>

<span class="k">def</span> <span class="nf">highway_dnn</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">keep_prob</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;highway_dnn&#39;</span><span class="p">):</span>
    <span class="n">activation</span> <span class="o">=</span> <span class="n">node_ops</span><span class="o">.</span><span class="n">ACTIVATION</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n_units</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;layer</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">):</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;hidden&#39;</span><span class="p">):</span>
                    <span class="n">hidden</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">node_ops</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="n">n_units</span><span class="p">,</span> <span class="bp">True</span><span class="p">))</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;transform&#39;</span><span class="p">):</span>
                    <span class="n">transform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">node_ops</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="n">n_units</span><span class="p">,</span> <span class="bp">True</span><span class="p">))</span>
                <span class="n">tensor_in</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">transform</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">keep_prob</span><span class="p">:</span>
                    <span class="n">tensor_in</span> <span class="o">=</span> <span class="n">node_ops</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensor_in</span>
</pre></div>
</div>
<p>This looks okay for a first approximation. However we would like to initialize the bias for the transform gate to some
negative value, so we have to set the optional <em>bias_start=0</em> parameter in the call to <a class="reference internal" href="node_ops.html#node_ops.linear" title="node_ops.linear"><code class="xref any py py-func docutils literal"><span class="pre">linear</span></code></a> for the transform gate to
a value we would like.</p>
<div class="admonition-todo admonition" id="index-1">
<p class="first admonition-title">Todo</p>
<p class="last">Alter the <strong>highway_dnn</strong> code to take an optional parameter for transform bias initialization. Replace <strong>dnn</strong> nodes
in tree.config with <strong>highway_dnn</strong> nodes.</p>
</div>
<p>Now we need to let the <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> constructor know about our new node by using the factory constructor <code class="xref any docutils literal"><span class="pre">graph_setup</span></code> with
one of the two optional arguments introducing new node functions. If
your new node definition is in it&#8217;s own module possibly full of other node definitions you have created you can use the
<em>imports</em> argument which is a dictionary with module names as keys and the paths to modules as values. In our case since we
have only made one new node function we will use the <em>function_map</em> parameter which takes a dictionary of function_name keys
and function values. So we replace our <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> constructor call as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;mfgraph&#39;</span><span class="p">):</span>
    <span class="n">ant</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_setup</span><span class="p">(</span><span class="s1">&#39;tree.config&#39;</span><span class="p">,</span>
                              <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">-</span><span class="n">dev</span><span class="p">,</span>
                              <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span>
                              <span class="n">function_map</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;highway_dnn&#39;</span><span class="p">:</span> <span class="n">highway_dnn</span><span class="p">},</span>
                              <span class="n">variable_bindings</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kfactors&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s1">&#39;initrange&#39;</span><span class="p">:</span><span class="mf">0.001</span><span class="p">})</span>
</pre></div>
</div>
<p>Here is an example config file and corresponding graphviz dot image adding non-linearity and a <strong>highway_dnn</strong> node.
Notice that since highway networks have a fixed dimension size for hidden layers we have used an intermediate <strong>dnn</strong> node
to map the input to a dimension we want.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>dotproduct x_dot_y()
-all_user dnn([$kfactors,$kfactors,$kfactors], activation=&#39;tanh&#39;,bn=True,keep_prob=None)
--tanh_user tf.nn.tanh()
---merge_user concat($kfactors)
----huser lookup(dataname=&#39;user&#39;, initrange=$initrange, shape=[None, $kfactors])
----hage dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----agelookup embedding()
------age placeholder(tf.float32)
------user placeholder(tf.int32)
----hsex dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----sexlookup embedding()
------sex_weights weights(&#39;tnorm&#39;, tf.float32, [2, $kfactors])
------sexes embedding()
-------sex placeholder(tf.int32)
-------user placeholder(tf.int32)
----hocc dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----occlookup embedding()
------occ_weights weights(&#39;tnorm&#39;, tf.float32, [21, $kfactors])
------occs embedding()
-------occ placeholder(tf.int32)
-------user placeholder(tf.int32)
----hzip dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----ziplookup embedding()
------zip_weights weights(&#39;tnorm&#39;, tf.float32, [1000, $kfactors])
------zips embedding()
-------zip placeholder(tf.int32)
-------user placeholder(tf.int32)
----husertime dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----time placeholder(tf.float32)
-all_item dnn([$kfactors,$kfactors,$kfactors], activation=&#39;tanh&#39;,bn=True,keep_prob=None)
--tanh_item tf.nn.tanh()
---merge_item concat($kfactors)
----hitem lookup(dataname=&#39;item&#39;, initrange=$initrange, shape=[None, $kfactors])
----hgenre dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----genrelookup embedding()
------genres placeholder(tf.float32)
------item placeholder(tf.int32)
----hmonth dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----monthlookup embedding()
------month_weights weights(&#39;tnorm&#39;, tf.float32, [12, $kfactors])
------months embedding()
-------month placeholder(tf.int32)
-------item placeholder(tf.int32)
----hyear dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----yearlookup embedding()
------year placeholder(tf.float32)
------item placeholder(tf.int32)
----htfidf dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----tfidflookup embedding()
------tfidf_doc_term placeholder(tf.float32)
------item placeholder(tf.int32)
----hitemtime dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----time placeholder(tf.float32)
-ibias lookup(dataname=&#39;item&#39;, shape=[None, 1], initrange=$initrange)
-ubias lookup(dataname=&#39;user&#39;, shape=[None, 1], initrange=$initrange)
</pre></div>
</div>
<img alt="_images/highway_nonlinear.png" class="align-center" src="_images/highway_nonlinear.png" />
<p>Now that we are familiar with the tricks for crafting new models we can engage in creative enterprise. We have been using
the scalar ratings targets for objectives, but there are also one hot targets for classification included in the dataset.</p>
<div class="admonition-todo admonition" id="index-2">
<p class="first admonition-title">Todo</p>
<p>Using the data provided, craft your own model, and do some preliminary testing to see how it performs against
the other models you have explored. If you run into a bug, contact me and I will try to address it but feel free
to just take note of the bug, abandon the effort, and try something else.
Some ideas:</p>
<blockquote>
<div><p>Classification</p>
<p>Multiple targets of regression and classification</p>
<p>A different combine function which has a multiplicative interaction between data streams</p>
<p>Combining data streams in a binary fashion (for item streams don&#8217;t combine all three at once)</p>
<p>Scale the regression targets and use the built in <a class="reference internal" href="node_ops.html#node_ops.cosine" title="node_ops.cosine"><code class="xref any py py-func docutils literal"><span class="pre">cosine</span></code></a> node function instead of <a class="reference internal" href="node_ops.html#node_ops.x_dot_y" title="node_ops.x_dot_y"><code class="xref any py py-func docutils literal"><span class="pre">x_dot_y</span></code></a></p>
<p>Make the branches dealing with indices linear, as they are in basic MF, and combine them later in the tree</p>
<p>Create an LSTM node that takes a sequence as input and outputs the last hidden state vector.</p>
</div></blockquote>
<p class="last">For this task results are not paramount. Think of a way to address the data that makes sense and explores the kind of
functionality you may want to employ the toolkit for.</p>
</div>
</div>


           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Aaron Tuor.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>