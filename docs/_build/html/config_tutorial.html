<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Config Tutorial &mdash; antk 0.3.0 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="antk 0.3.0 documentation" href="index.html" />
    <link rel="up" title="config" href="config.html" />
    <link rel="next" title="node_ops" href="node_ops.html" />
    <link rel="prev" title="config" href="config.html" /> 
  </head>
  <body role="document">

<div style="background-color: white; text-align: center; padding: 10px 10px 15px 15px">
<a href="index.html"><img src="_static/antlogo.png" border="0" alt="ant logo"/></a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="node_ops.html" title="node_ops"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="config.html" title="config"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>

          <li class="nav-item nav-item-1"><a href="api.html" >API: ANT modules</a> &raquo;</li>
          <li class="nav-item nav-item-2"><a href="config.html" accesskey="U">config</a> &raquo;</li> 
      </ul>
    </div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Config Tutorial</a><ul>
<li><a class="reference internal" href="#terms">Terms</a></li>
<li><a class="reference internal" href="#graph-markers">Graph Markers</a></li>
<li><a class="reference internal" href="#node-names">Node Names</a></li>
<li><a class="reference internal" href="#examples">Examples</a></li>
<li><a class="reference internal" href="#node-functions">Node Functions</a></li>
<li><a class="reference internal" href="#the-antgraph-object">The AntGraph object</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="config.html"
                        title="previous chapter">config</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="node_ops.html"
                        title="next chapter">node_ops</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/config_tutorial.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="config-tutorial">
<h1>Config Tutorial<a class="headerlink" href="#config-tutorial" title="Permalink to this headline">¶</a></h1>
<p>The config module defines the <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> class.
The basic idea is to represent any directed acyclic graph (DAG) of higher level tensorflow operations
in a condensed and visually readable format. Here is a picture of a DAG of operations
derived from it&#8217;s representation in .config format:</p>
<img alt="_images/treedot.png" class="align-center" src="_images/treedot.png" />
<p>Here are contents of the corresponding .config file:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>dotproduct x_dot_y()
-all_user dnn([$kfactors,$kfactors,$kfactors], activation=&#39;tanh&#39;,bn=True,keep_prob=None)
--tanh_user tf.nn.tanh()
---merge_user concat($kfactors)
----huser lookup(dataname=&#39;user&#39;, initrange=$initrange, shape=[None, $kfactors])
----hage dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----agelookup embedding()
------age placeholder(tf.float32)
------user placeholder(tf.int32)
----hsex dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----sexlookup embedding()
------sex_weights weights(&#39;tnorm&#39;, tf.float32, [2, $kfactors])
------sexes embedding()
-------sex placeholder(tf.int32)
-------user placeholder(tf.int32)
----hocc dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----occlookup embedding()
------occ_weights weights(&#39;tnorm&#39;, tf.float32, [21, $kfactors])
------occs embedding()
-------occ placeholder(tf.int32)
-------user placeholder(tf.int32)
----hzip dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----ziplookup embedding()
------zip_weights weights(&#39;tnorm&#39;, tf.float32, [1000, $kfactors])
------zips embedding()
-------zip placeholder(tf.int32)
-------user placeholder(tf.int32)
----husertime dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----time placeholder(tf.float32)
-all_item dnn([$kfactors,$kfactors,$kfactors], activation=&#39;tanh&#39;,bn=True,keep_prob=None)
--tanh_item tf.nn.tanh()
---merge_item concat($kfactors)
----hitem lookup(dataname=&#39;item&#39;, initrange=$initrange, shape=[None, $kfactors])
----hgenre dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----genrelookup embedding()
------genre placeholder(tf.float32)
------item placeholder(tf.int32)
----hmonth dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----monthlookup embedding()
------month_weights weights(&#39;tnorm&#39;, tf.float32, [12, $kfactors])
------months embedding()
-------month placeholder(tf.int32)
-------item placeholder(tf.int32)
----hyear dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----yearlookup embedding()
------year placeholder(tf.float32)
------item placeholder(tf.int32)
----htfidf dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----tfidflookup embedding()
------tfidf_doc_term placeholder(tf.float32)
------item placeholder(tf.int32)
----hitemtime dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----time placeholder(tf.float32)
-ibias lookup(dataname=&#39;item&#39;, shape=[None, 1], initrange=$initrange)
-ubias lookup(dataname=&#39;user&#39;, shape=[None, 1], initrange=$initrange)
</pre></div>
</div>
<p>The lines in the .config file consist of a possibly empty graph marker, followed by a node name, followed by a node function call.
We will discuss each of these in turn.</p>
<div class="section" id="terms">
<h2>Terms<a class="headerlink" href="#terms" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p><strong>Node description</strong>: A line in a .config file</p>
<dl class="docutils">
<dt><strong>Graph marker</strong>: A character or sequence of characters that delimits graph dependencies. Specified by the graph marker parameter</dt>
<dd>for the constructor to AntGraph. By default &#8216;-&#8216;.</dd>
</dl>
<p><strong>Node name</strong>: The first thing on a line in a .config file after a possibly empty sequence of graph markers and possible whitespace.</p>
<dl class="docutils">
<dt><strong>Node function</strong>: A function which takes as its first argument a tensor or structured list of tensors, returns</dt>
<dd>a tensor, or structured list of tensors, and has an optional name argument.</dd>
</dl>
<p><strong>Node function call</strong>: The last item in a node description.</p>
</div></blockquote>
</div>
<div class="section" id="graph-markers">
<h2>Graph Markers<a class="headerlink" href="#graph-markers" title="Permalink to this headline">¶</a></h2>
<p>In the .config file depicted above the graph marker is &#8216;-&#8216;. The graph markers in a .config file define the edges of
the DAG. Lines in a .config file with no graph markers represent nodes with outorder = 0.
These are the &#8216;roots&#8217; of the DAG. The graph representation in .config format is similar to a textual tree or forest
representation, however, multiple lines may refer to the same node. For each node description of a node, there is an edge from
this node to the node described by the first line above of this node description that has one less graph marker.</p>
</div>
<div class="section" id="node-names">
<h2>Node Names<a class="headerlink" href="#node-names" title="Permalink to this headline">¶</a></h2>
<p>The next thing on a line following a possibly empty sequence of graph markers is the node name. Node names are used
for unique <a class="reference external" href="https://www.tensorflow.org/versions/r0.7/how_tos/variable_scope/index.html">variable scope</a> of the tensors created by the node function call. The number of
nodes in a graph</p>
<blockquote>
<div>is the number of unique</div></blockquote>
<p>node names in the .config file.</p>
</div>
<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h2>
<p>The best way to get a feel for how to construct a DAG in this format is to try some things out. Since node function calls
have no bearing on the high level structure of the computational graph let&#8217;s simplify things
and omit the node function calls for now. This won&#8217;t be acceptable .config
syntax but it will help us focus on the exploration of this form of graph representation.</p>
<p>Here is a .config file minus the function calls (notice the optional whitespace before graph markers):</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">dotproduct</span>
    <span class="o">-</span><span class="n">huser</span>
    <span class="o">-</span><span class="n">hitem</span>
    <span class="o">-</span><span class="n">ibias</span>
    <span class="o">-</span><span class="n">ubias</span>
</pre></div>
</div>
<p>Save this content in a file called test.config.
Now in an interpreter:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="go">&gt;&gt;&gt;from antk.core import config</span>
<span class="go">&gt;&gt;&gt;config.testGraph(&#39;test.config&#39;)</span>
</pre></div>
</div>
<p>This image should display:</p>
<img alt="_images/no_name.png" class="align-center" src="_images/no_name.png" />
<p>Now experiment with test.config to make some more graphs.</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="n">dotproduct</span>
    <span class="o">-</span><span class="n">huser</span>
        <span class="o">--</span><span class="n">hitem</span>
    <span class="o">-</span><span class="n">ibias</span>
        <span class="o">--</span><span class="n">hitem</span>
    <span class="o">-</span><span class="n">ubias</span>
        <span class="o">--</span><span class="n">hitem</span>
    <span class="o">-</span><span class="n">hitem</span>
</pre></div>
</td></tr></table></div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><strong>Repeated Node Names</strong> Graph traversal proceeds in the fashion of a postorder tree traversal.
When node names are repeated in a .config file, the output of this node is the output of the node description with this
name which is first encountered in graph traversal.
So, for the above example .config file and its corresponding picture below, the output of the hitem node would be the
output of the node function call (omitted) on line
3. The order in which the nodes are evaluated for the config above is: <strong>hitem</strong>, <strong>huser</strong>, <strong>ibias</strong>, <strong>ubias</strong>,
<strong>dotproduct</strong>.</p>
</div>
<img alt="_images/ex1.png" class="align-center" src="_images/ex1.png" />
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">dotproduct</span>
    <span class="o">-</span><span class="n">huser</span>
        <span class="o">--</span><span class="n">hitem</span>
    <span class="o">-</span><span class="n">ibias</span>
        <span class="o">--</span><span class="n">hitem</span>
    <span class="o">-</span><span class="n">ubias</span>
        <span class="o">--</span><span class="n">hitem</span>
    <span class="o">-</span><span class="n">hitem</span>
<span class="n">a</span>
<span class="n">b</span>
<span class="n">c</span>
<span class="n">d</span>
</pre></div>
</div>
<img alt="_images/ex2.png" class="align-center" src="_images/ex2.png" />
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last"><strong>Cycles</strong>: ANTk is designed to create directed acyclic graphs of operations from a config file,
so cycles are not allowed.
Below is an example of a config setup that describes a cycle. This config would cause an error, even if the node function
calls were made with proper inputs.</p>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">hitem</span>
    <span class="o">-</span><span class="n">huser</span>
        <span class="o">--</span><span class="n">hitem</span>
    <span class="o">-</span><span class="n">ibias</span>
        <span class="o">--</span><span class="n">hitem</span>
    <span class="o">-</span><span class="n">ubias</span>
        <span class="o">--</span><span class="n">hitem</span>
    <span class="o">-</span><span class="n">hitem</span>
</pre></div>
</div>
<img alt="_images/ex3.png" class="align-center" src="_images/ex3.png" />
</div>
<div class="section" id="node-functions">
<h2>Node Functions<a class="headerlink" href="#node-functions" title="Permalink to this headline">¶</a></h2>
<p>The first and only thing that comes after the name in a node description is a node function call.
Node functions always take tensors or structured lists of tensors as input, return tensors or structured lists of tensors
as output, and have an optional name argument.
The syntax for a node function call in a .config is the same as calling the function in a python script,
but omitting the first tensor input argument and the name argument. The tensor input is derived from the graph. A node&#8217;s
tensor input is a list of the output of it&#8217;s &#8216;child&#8217; nodes&#8217; (nodes with edges directed to this node) function calls. If
a node has inorder = 1 then its input is a single tensor as opposed to a list of tensors of length 1.</p>
<p>Any node functions defined in <a class="reference internal" href="node_ops.html"><span class="doc">node_ops</span></a> may be used in a graph, as well as any tensorflow functions which satisfy the
definition of a node function. For tensorflow node function calls &#8216;tensorflow&#8217; is abbreviated to &#8216;tf&#8217;.
User defined node functions may be used in the graph when specified by the optional
arguments <em>function_map</em>, and <em>imports</em>, to the <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> constructor.</p>
<p>The node name is used for the optional name argument of the node function.</p>
</div>
<div class="section" id="the-antgraph-object">
<h2>The AntGraph object<a class="headerlink" href="#the-antgraph-object" title="Permalink to this headline">¶</a></h2>
<p>To use a .config file to build a tensorflow computational graph you call the <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> constructor with the
path to the .config file as the first argument, and some other optional arguments. We&#8217;ll make the multinomial logistic
regression model from tensorflow&#8217;s basic <a class="reference external" href="https://www.tensorflow.org/versions/r0.7/tutorials/mnist/beginners/index.html">MNIST tutorial</a>, and then extend this model to a deep neural network
in order to demonstrate how to use a .config file in your tensorflow code.</p>
<p>Create a file called antk_mnist.py and start off by importing the modules and data we need.</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">antk.core</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="kn">import</span> <span class="n">input_data</span>

<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s2">&quot;MNIST_data/&quot;</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<p>We&#8217;ll need a config file called logreg.config with the content below:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">pred</span> <span class="n">mult_log_reg</span><span class="p">(</span><span class="n">numclasses</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="o">-</span><span class="n">pixels</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>Notice that we didn&#8217;t specify any dimensions for the placeholder <em>pixels</em>. We need to hand a dictionary with keys corresponding
to placeholders with unspecified dimensions, and values of the data that will later get fed to this placeholder during
graph execution. This way the constructor will infer the shape of the placeholder. This practice can
help eliminate a common source of errors in constructing a tensorflow graph. To instantiate the graph from this config
file we add to antk_mnist.py:</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>6
7
8
9</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;antgraph&#39;</span><span class="p">):</span>
    <span class="n">antgraph</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">AntGraph</span><span class="p">(</span><span class="s1">&#39;logreg.config&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;pixels&#39;</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="p">})</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">antgraph</span><span class="o">.</span><span class="n">placeholderdict</span><span class="p">[</span><span class="s1">&#39;pixels&#39;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">antgraph</span><span class="o">.</span><span class="n">tensor_out</span>
</pre></div>
</td></tr></table></div>
<p>There are three accessible fields of a <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> object which contain tensors created during graph construction from
a .config file:</p>
<ul class="simple">
<li><a class="reference internal" href="config.html#config.AntGraph.tensordict" title="config.AntGraph.tensordict"><code class="xref any py py-attr docutils literal"><span class="pre">tensordict</span></code></a>: a python dictionary of non-placeholder tensors.</li>
<li><a class="reference internal" href="config.html#config.AntGraph.placeholderdict" title="config.AntGraph.placeholderdict"><code class="xref any py py-attr docutils literal"><span class="pre">placeholderdict</span></code></a>: a python dictionary of placeholder tensors.</li>
<li><a class="reference internal" href="config.html#config.AntGraph.tensor_out" title="config.AntGraph.tensor_out"><code class="xref any py py-attr docutils literal"><span class="pre">tensor_out</span></code></a>: The output of the nodes of the graph with outorder 0 (no graph markers).</li>
</ul>
<p>Note that we could replace line 9 above with the following:</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>9</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">antgraph</span><span class="o">.</span><span class="n">tensordict</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span>
</pre></div>
</td></tr></table></div>
<p>We can now complete the simple MNIST model verbatim from the tensorflow tutorial:</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="n">y_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">cross_entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">y_</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">)</span>

<span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="c1"># tensorboard stuff</span>
<span class="n">accuracy_summary</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">scalar_summary</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">SummaryWriter</span><span class="p">(</span><span class="s1">&#39;log/logistic_regression&#39;</span><span class="p">,</span> <span class="n">session</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_graph_def</span><span class="p">())</span>
<span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">initialize_all_variables</span><span class="p">())</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">batch_xs</span><span class="p">,</span> <span class="n">y_</span><span class="p">:</span> <span class="n">batch_ys</span><span class="p">})</span>

    <span class="n">acc</span><span class="p">,</span> <span class="n">summary_str</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">accuracy_summary</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="p">,</span>
                                           <span class="n">y_</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">labels</span><span class="p">})</span>
    <span class="n">summary_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary_str</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;epoch: </span><span class="si">%f</span><span class="s1"> acc: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mf">100.0</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">acc</span><span class="p">))</span>
</pre></div>
</td></tr></table></div>
<p>If we let antk_mnist.py take a command line argument for a .config file
we can use antk_mnist.py with any number of .config files expressing arbitrarily complex architectures. This will
allow us to quickly search for a better model. Let&#8217;s use the argparse module to get this command line argument by
adding the following lines to antk_mnist.py.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">argparse</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Model for training arbitrary MNIST digit recognition architectures.&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The config file for building the ant architecture.&quot;</span><span class="p">)</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
</pre></div>
</div>
<p>Now we change the former line 7 to:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">antgraph</span> <span class="o">=</span> <span class="n">AntGraph</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;pixels&#39;</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">images</span><span class="p">})</span>
</pre></div>
</div>
<p>We could try a neural network with nnet_mnist.config:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">pred</span> <span class="n">mult_log_reg</span><span class="p">(</span><span class="n">numclasses</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="o">-</span><span class="n">network</span> <span class="n">dnn</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">)</span>
<span class="o">--</span><span class="n">pixels</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>This should get us to about .94 accuracy.
We might want to parameterize the number of hidden nodes per hidden layer or the activation function. For this
we can use some more command line arguments, and the config file variable marker &#8216;$&#8217;.</p>
<p>First we change nnet_mnist.config as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>pred mult_log_reg(numclasses=10)
-network dnn([$h1, $h2, $h3], activation=$act)
--pixels placeholder(tf.float32)
</pre></div>
</div>
<p>Next we need some more command line arguments for antk_mnist.py. So we need to add these lines:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-h1&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of hidden nodes in layer 1.&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-h2&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of hidden nodes in layer 2.&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-h3&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of hidden nodes in layer 3.&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-act&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Type of activation function.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally we need to bind the variables in the .config file in our call to the <a class="reference internal" href="config.html#config.AntGraph" title="config.AntGraph"><code class="xref any py py-class docutils literal"><span class="pre">AntGraph</span></code></a> constructor
using the optional <em>variable_bindings</em> argument.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;antgraph&#39;</span><span class="p">):</span>
    <span class="n">antgraph</span> <span class="o">=</span> <span class="n">AntGraph</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;pixels&#39;</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">images</span><span class="p">},</span>
                        <span class="n">variable_bindings</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;h1&#39;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">h1</span><span class="p">,</span>
                                           <span class="s1">&#39;h2&#39;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">h2</span><span class="p">,</span>
                                           <span class="s1">&#39;h3&#39;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">h3</span><span class="p">,</span>
                                           <span class="s1">&#39;act&#39;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">act</span><span class="p">})</span>
</pre></div>
</div>
<p>For something really deep we might try a highway network with high_mnist.config:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">pred</span> <span class="n">mult_log_reg</span><span class="p">(</span><span class="n">numclasses</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="o">-</span><span class="n">network3</span> <span class="n">dnn</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>
<span class="o">--</span><span class="n">network2</span> <span class="n">highway_dnn</span><span class="p">([</span><span class="mi">50</span><span class="p">]</span><span class="o">*</span><span class="mi">20</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">bn</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="o">---</span><span class="n">network</span> <span class="n">dnn</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>
<span class="o">----</span><span class="n">pixels</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>This may take 5 or 10 minutes to train but should get around .96 accuracy.</p>
<p>These higher level abstractions are nice for automating the creation of weight and bias <a class="reference external" href="https://www.tensorflow.org/versions/r0.7/how_tos/variables/index.html">Variables</a>, and the
<a class="reference external" href="https://www.tensorflow.org/versions/r0.7/api_docs/python/framework.html#Tensor">Tensors</a> involved a deep neural network architecture. However, one may need direct access to tensors created within
a complex operation such as <em>highway_dnn</em>, to for instance analyze the training of a model. There is access to these
tensors via a standard tensorflow function and some collections associated with each node defined in the .config
file. To demonstrate accessing the tensors created by the <em>highway_dnn</em> operation in high_mnist.config, at the end of
antk_mnist.py we can add:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;network&#39;</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;network_bias&#39;</span><span class="p">)</span>
<span class="n">other</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;network&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">wght</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;weight </span><span class="si">%d</span><span class="s1">: name=</span><span class="si">%s</span><span class="s1"> tensor=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">wght</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">wght</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bias</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;bias </span><span class="si">%d</span><span class="s1">: name=</span><span class="si">%s</span><span class="s1"> tensor=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">other</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;other </span><span class="si">%d</span><span class="s1">: name=</span><span class="si">%s</span><span class="s1"> tensor=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">))</span>
</pre></div>
</div>
<p>And post training we get the following output modulo two memory addresses:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>weight 0: name=antgraph/network/layer0/add:0 tensor=Tensor(&quot;antgraph/network/layer0/add:0&quot;, shape=(?, 100), dtype=float32)
weight 1: name=antgraph/network/layer1/add:0 tensor=Tensor(&quot;antgraph/network/layer1/add:0&quot;, shape=(?, 50), dtype=float32)
bias 0: name=network/layer0/network/Bias:0 tensor=&lt;tensorflow.python.ops.variables.Variable object at 0x7f1b90764350&gt;
bias 1: name=network/layer1/network/Bias:0 tensor=&lt;tensorflow.python.ops.variables.Variable object at 0x7f1b90723d50&gt;
other 0: name=antgraph/network/layer0/add:0 tensor=Tensor(&quot;antgraph/network/layer0/add:0&quot;, shape=(?, 100), dtype=float32)
other 1: name=antgraph/network/layer1/add:0 tensor=Tensor(&quot;antgraph/network/layer1/add:0&quot;, shape=(?, 50), dtype=float32)
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="node_ops.html" title="node_ops"
             >next</a> |</li>
        <li class="right" >
          <a href="config.html" title="config"
             >previous</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>

          <li class="nav-item nav-item-1"><a href="api.html" >API: ANT modules</a> &raquo;</li>
          <li class="nav-item nav-item-2"><a href="config.html" >config</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2016, Aaron Tuor.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.4.5.
    </div>
  </body>
</html>