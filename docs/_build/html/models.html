<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Models &mdash; antk 0.3.0 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="antk 0.3.0 documentation" href="index.html" />
    <link rel="up" title="API: ANT modules" href="api.html" />
    <link rel="next" title="Tutorials" href="tutorials.html" />
    <link rel="prev" title="generic_model" href="generic_model.html" /> 
  </head>
  <body role="document">

<div style="background-color: white; text-align: center; padding: 10px 10px 15px 15px">
<a href="index.html"><img src="_static/antlogo.png" border="0" alt="ant logo"/></a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="tutorials.html" title="Tutorials"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="generic_model.html" title="generic_model"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>

          <li class="nav-item nav-item-1"><a href="api.html" accesskey="U">API: ANT modules</a> &raquo;</li> 
      </ul>
    </div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Models</a><ul>
<li><a class="reference internal" href="#module-skipgram">Skipgram</a></li>
<li><a class="reference internal" href="#module-mfmodel">Matrix Factorization</a><ul>
<li><a class="reference internal" href="#sample-config">Sample Config</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-dssm_model">DSSM (Deep Structured Semantic Model) Variant</a><ul>
<li><a class="reference internal" href="#id4">Sample Config</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-dsaddmodel">Weighted DSSM variant</a></li>
<li><a class="reference internal" href="#module-tree_model">Binary Tree of Deep Neural Networks for Multiple Inputs</a><ul>
<li><a class="reference internal" href="#id5">Sample Config</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-dnn_concat_model">A Deep Neural Network with Concatenated Input Streams</a><ul>
<li><a class="reference internal" href="#id6">Sample Config</a></li>
</ul>
</li>
<li><a class="reference internal" href="#multiplicative-interaction-between-text-user-and-item">Multiplicative Interaction between Text, User, and Item</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="generic_model.html"
                        title="previous chapter">generic_model</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="tutorials.html"
                        title="next chapter">Tutorials</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/models.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="models">
<h1>Models<a class="headerlink" href="#models" title="Permalink to this headline">¶</a></h1>
<p>The models below are available in ANTk. If the model takes a config file then a sample config is provided.</p>
<div class="section" id="module-skipgram">
<span id="skipgram"></span><h2>Skipgram<a class="headerlink" href="#module-skipgram" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="skipgram.SkipGramVecs">
<em class="property">class </em><code class="descclassname">skipgram.</code><code class="descname">SkipGramVecs</code><span class="sig-paren">(</span><em>textfile</em>, <em>vocabulary_size=12735</em>, <em>batch_size=128</em>, <em>embedding_size=128</em>, <em>skip_window=1</em>, <em>num_skips=2</em>, <em>valid_size=16</em>, <em>valid_window=100</em>, <em>num_sampled=64</em>, <em>num_steps=100000</em>, <em>verbose=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/skipgram.html#SkipGramVecs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skipgram.SkipGramVecs" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains a skip gram model from <a class="reference external" href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Distributed Representations of Words and Phrases and their Compositionality</a></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>textfile</strong> &#8211; Plain text file or zip file with plain text files.</li>
<li><strong>vocabulary_size</strong> &#8211; How many words to use from text</li>
<li><strong>batch_size</strong> &#8211; mini-batch size</li>
<li><strong>embedding_size</strong> &#8211; Dimension of the embedding vector.</li>
<li><strong>skip_window</strong> &#8211; How many words to consider left and right.</li>
<li><strong>num_skips</strong> &#8211; How many times to reuse an input to generate a label.</li>
<li><strong>valid_size</strong> &#8211; Random set of words to evaluate similarity on.</li>
<li><strong>valid_window</strong> &#8211; Only pick dev samples in the head of the distribution.</li>
<li><strong>num_sampled</strong> &#8211; Number of negative examples to sample.</li>
<li><strong>num_steps</strong> &#8211; How many mini-batch steps to take</li>
<li><strong>verbose</strong> &#8211; Whether to calculate and print similarities for a sample of words</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="skipgram.SkipGramVecs.plot_embeddings">
<code class="descname">plot_embeddings</code><span class="sig-paren">(</span><em>filename='tsne.png'</em>, <em>num_terms=500</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/skipgram.html#SkipGramVecs.plot_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skipgram.SkipGramVecs.plot_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot tsne reduction of learned word embeddings in 2-space.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>filename</strong> &#8211; File to save plot to.</li>
<li><strong>num_terms</strong> &#8211; How many words to plot.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="skipgram.build_dataset">
<code class="descclassname">skipgram.</code><code class="descname">build_dataset</code><span class="sig-paren">(</span><em>words</em>, <em>vocabulary_size</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/skipgram.html#build_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skipgram.build_dataset" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>words</strong> &#8211; A list of word tokens from a text file</li>
<li><strong>vocabulary_size</strong> &#8211; How many word tokens to keep.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">data (text transformed into list of word ids &#8216;UNK&#8217;=0), count (list of pairs (word:word_count) indexed by word id), dictionary (word:id hashmap), reverse_dictionary (id:word hashmap)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="skipgram.generate_batch">
<code class="descclassname">skipgram.</code><code class="descname">generate_batch</code><span class="sig-paren">(</span><em>data</em>, <em>batch_size</em>, <em>num_skips</em>, <em>skip_window</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/skipgram.html#generate_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skipgram.generate_batch" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> &#8211; list of word ids corresponding to text</li>
<li><strong>batch_size</strong> &#8211; Size of batch to retrieve</li>
<li><strong>num_skips</strong> &#8211; How many times to reuse an input to generate a label.</li>
<li><strong>skip_window</strong> &#8211; How many words to consider left and right.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="skipgram.plot_tsne">
<code class="descclassname">skipgram.</code><code class="descname">plot_tsne</code><span class="sig-paren">(</span><em>embeddings</em>, <em>labels</em>, <em>filename='tsne.png'</em>, <em>num_terms=500</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/skipgram.html#plot_tsne"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skipgram.plot_tsne" title="Permalink to this definition">¶</a></dt>
<dd><p>Makes tsne plot to visualize word embeddings. Need sklearn, matplotlib for this to work.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>filename</strong> &#8211; Location to save labeled tsne plots</li>
<li><strong>num_terms</strong> &#8211; Num of words to plot</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="skipgram.read_data">
<code class="descclassname">skipgram.</code><code class="descname">read_data</code><span class="sig-paren">(</span><em>filename</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/skipgram.html#read_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skipgram.read_data" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>filename</strong> &#8211; A zip file to open and read from</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A list of the space delimited tokens from the textfile.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-mfmodel">
<span id="matrix-factorization"></span><h2>Matrix Factorization<a class="headerlink" href="#module-mfmodel" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="mfmodel.mf">
<code class="descclassname">mfmodel.</code><code class="descname">mf</code><span class="sig-paren">(</span><em>data</em>, <em>configfile</em>, <em>lamb=0.001</em>, <em>kfactors=20</em>, <em>learnrate=0.01</em>, <em>verbose=True</em>, <em>epochs=1000</em>, <em>maxbadcount=20</em>, <em>mb=500</em>, <em>initrange=1</em>, <em>eval_rate=500</em>, <em>random_seed=None</em>, <em>develop=False</em>, <em>train_dev_eval_factor=3</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mfmodel.html#mf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mfmodel.mf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<div class="section" id="sample-config">
<h3>Sample Config<a class="headerlink" href="#sample-config" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">dotproduct</span> <span class="n">x_dot_y</span><span class="p">()</span>
    <span class="o">-</span><span class="n">huser</span> <span class="n">lookup</span><span class="p">(</span><span class="n">dataname</span><span class="o">=</span><span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="n">initrange</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>
    <span class="o">-</span><span class="n">hitem</span> <span class="n">lookup</span><span class="p">(</span><span class="n">dataname</span><span class="o">=</span><span class="s1">&#39;item&#39;</span><span class="p">,</span> <span class="n">initrange</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>
    <span class="o">-</span><span class="n">ibias</span> <span class="n">lookup</span><span class="p">(</span><span class="n">dataname</span><span class="o">=</span><span class="s1">&#39;item&#39;</span><span class="p">,</span> <span class="n">initrange</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="o">-</span><span class="n">ubias</span> <span class="n">lookup</span><span class="p">(</span><span class="n">dataname</span><span class="o">=</span><span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="n">initrange</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>Low Rank Matrix Factorization is a popular machine learning technique used to produce recommendations
given a set of ratings a user has given an item. The known ratings are collected in a user-item utility matrix
and the missing entries are predicted by optimizing a low rank factorization of the utility matrix given the known
entries. The basic idea behind matrix factorization models is that the information encoded for items
in the columns of the utility matrix, and for users in the rows of the utility matrix is not
exactly independent. We optimize the objective function <span class="math">\(\sum_{(u,i)} (R_{ui} - P_i^T U_u)^2\)</span> over the observed
ratings for user <em>u</em> and item <em>i</em> using gradient descent.</p>
<img alt="_images/factormodel.png" class="align-center" src="_images/factormodel.png" />
<p>We can express the same optimization in the form of a computational graph that will play nicely with tensorflow:</p>
<img alt="_images/graphmf.png" class="align-center" src="_images/graphmf.png" />
<p>Here <span class="math">\(xitem_i\)</span>, and <span class="math">\(xuser_j\)</span> are some representation of the indices for the user and item vectors in the utility matrix.
These could be one hot vectors, which can then be matrix multiplied by the <em>P</em> and <em>U</em> matrices to select the corresponding
user and item vectors. In practice it is much faster to let <span class="math">\(xitem_i\)</span>, and <span class="math">\(xuser_j\)</span> be vectors of indices
which can be used by tensorflow&#8217;s <strong>gather</strong> or <strong>embedding_lookup</strong> functions to select the corresponding vector from
the <em>P</em> and <em>U</em> matrices.</p>
</div>
</div>
<div class="section" id="module-dssm_model">
<span id="dssm-deep-structured-semantic-model-variant"></span><h2>DSSM (Deep Structured Semantic Model) Variant<a class="headerlink" href="#module-dssm_model" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="dssm_model.dssm">
<code class="descclassname">dssm_model.</code><code class="descname">dssm</code><span class="sig-paren">(</span><em>data, configfile, layers=[10, 10, 10], bn=True, keep_prob=0.95, act='tanhlecun', initrange=1, kfactors=10, lamb=0.1, mb=500, learnrate=0.0001, verbose=True, maxbadcount=10, epochs=100, model_name='dssm', random_seed=500, eval_rate=500</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dssm_model.html#dssm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dssm_model.dssm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<img alt="_images/dssm.png" class="align-center" src="_images/dssm.png" />
<div class="section" id="id4">
<h3>Sample Config<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span></span>dotproduct x_dot_y()
-user_vecs ident()
--huser lookup(dataname=&#39;user&#39;, initrange=$initrange, shape=[None, $kfactors])
--hage dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=.8)
---agelookup embedding()
----age placeholder(tf.float32)
----user placeholder(tf.int32)
--hsex dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
---sexlookup embedding()
----sex_weights weights(&#39;tnorm&#39;, tf.float32, [2, $kfactors])
----sexes embedding()
-----sex placeholder(tf.int32)
-----user placeholder(tf.int32)
--hocc dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
---occlookup embedding()
----occ_weights weights(&#39;tnorm&#39;, tf.float32, [21, $kfactors])
----occs embedding()
-----occ placeholder(tf.int32)
-----user placeholder(tf.int32)
--hzip dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
---ziplookup embedding()
----zip_weights weights(&#39;tnorm&#39;, tf.float32, [1000, $kfactors])
----zips embedding()
-----zip placeholder(tf.int32)
-----user placeholder(tf.int32)
--husertime dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
---time placeholder(tf.float32)
-item_vecs ident()
--hitem lookup(dataname=&#39;item&#39;, initrange=$initrange, shape=[None, $kfactors])
--hgenre dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
---genrelookup embedding()
----genres placeholder(tf.float32)
----item placeholder(tf.int32)
--hmonth dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
---monthlookup embedding()
----month_weights weights(&#39;tnorm&#39;, tf.float32, [12, $kfactors])
----months embedding()
-----month placeholder(tf.int32)
-----item placeholder(tf.int32)
--hyear dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
---yearlookup embedding()
----year placeholder(tf.float32)
----item placeholder(tf.int32)
--htfidf dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
---tfidflookup embedding()
----tfidf_doc_term placeholder(tf.float32)
----item placeholder(tf.int32)
--hitemtime dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
---time placeholder(tf.float32)
-ibias lookup(dataname=&#39;item&#39;, shape=[None, 1], initrange=$initr
</pre></div>
</div>
</div>
</div>
<div class="section" id="module-dsaddmodel">
<span id="weighted-dssm-variant"></span><h2>Weighted DSSM variant<a class="headerlink" href="#module-dsaddmodel" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="dsaddmodel.dsadd">
<code class="descclassname">dsaddmodel.</code><code class="descname">dsadd</code><span class="sig-paren">(</span><em>data</em>, <em>configfile</em>, <em>initrange=0.1</em>, <em>kfactors=20</em>, <em>lamb=0.01</em>, <em>mb=500</em>, <em>learnrate=0.003</em>, <em>verbose=True</em>, <em>maxbadcount=10</em>, <em>epochs=100</em>, <em>model_name='dssm'</em>, <em>random_seed=500</em>, <em>eval_rate=500</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dsaddmodel.html#dsadd"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dsaddmodel.dsadd" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<p>This model is the same architecture as the variant of DSSM above but with a different loss:</p>
<img alt="_images/weightedloss.png" class="align-center" src="_images/weightedloss.png" />
</div>
<div class="section" id="module-tree_model">
<span id="binary-tree-of-deep-neural-networks-for-multiple-inputs"></span><h2>Binary Tree of Deep Neural Networks for Multiple Inputs<a class="headerlink" href="#module-tree_model" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="tree_model.tree">
<code class="descclassname">tree_model.</code><code class="descname">tree</code><span class="sig-paren">(</span><em>data</em>, <em>configfile</em>, <em>lamb=0.001</em>, <em>kfactors=20</em>, <em>learnrate=0.0001</em>, <em>verbose=True</em>, <em>maxbadcount=20</em>, <em>mb=500</em>, <em>initrange=1e-05</em>, <em>epochs=10</em>, <em>random_seed=None</em>, <em>eval_rate=500</em>, <em>keep_prob=0.95</em>, <em>act='tanh'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tree_model.html#tree"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tree_model.tree" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<img alt="_images/tree1.png" class="align-center" src="_images/tree1.png" />
<div class="section" id="id5">
<h3>Sample Config<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span></span>dotproduct x_dot_y()
-all_user dnn([$kfactors,$kfactors,$kfactors], activation=&#39;tanh&#39;,bn=True,keep_prob=None)
--tanh_user tf.nn.tanh()
---merge_user concat($kfactors)
----huser lookup(dataname=&#39;user&#39;, initrange=$initrange, shape=[None, $kfactors])
----hage dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----agelookup embedding()
------age placeholder(tf.float32)
------user placeholder(tf.int32)
----hsex dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----sexlookup embedding()
------sex_weights weights(&#39;tnorm&#39;, tf.float32, [2, $kfactors])
------sexes embedding()
-------sex placeholder(tf.int32)
-------user placeholder(tf.int32)
----hocc dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----occlookup embedding()
------occ_weights weights(&#39;tnorm&#39;, tf.float32, [21, $kfactors])
------occs embedding()
-------occ placeholder(tf.int32)
-------user placeholder(tf.int32)
----hzip dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----ziplookup embedding()
------zip_weights weights(&#39;tnorm&#39;, tf.float32, [1000, $kfactors])
------zips embedding()
-------zip placeholder(tf.int32)
-------user placeholder(tf.int32)
----husertime dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----time placeholder(tf.float32)
-all_item dnn([$kfactors,$kfactors,$kfactors], activation=&#39;tanh&#39;,bn=True,keep_prob=None)
--tanh_item tf.nn.tanh()
---merge_item concat($kfactors)
----hitem lookup(dataname=&#39;item&#39;, initrange=$initrange, shape=[None, $kfactors])
----hgenre dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----genrelookup embedding()
------genres placeholder(tf.float32)
------item placeholder(tf.int32)
----hmonth dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----monthlookup embedding()
------month_weights weights(&#39;tnorm&#39;, tf.float32, [12, $kfactors])
------months embedding()
-------month placeholder(tf.int32)
-------item placeholder(tf.int32)
----hyear dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----yearlookup embedding()
------year placeholder(tf.float32)
------item placeholder(tf.int32)
----htfidf dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----tfidflookup embedding()
------tfidf_doc_term placeholder(tf.float32)
------item placeholder(tf.int32)
----hitemtime dnn([$kfactors,$kfactors,$kfactors],activation=&#39;tanh&#39;,bn=True,keep_prob=None)
-----time placeholder(tf.float32)
-ibias lookup(dataname=&#39;item&#39;, shape=[None, 1], initrange=$initrange)
-ubias lookup(dataname=&#39;user&#39;, shape=[None, 1], initrange=$initrange)
</pre></div>
</div>
</div>
</div>
<div class="section" id="module-dnn_concat_model">
<span id="a-deep-neural-network-with-concatenated-input-streams"></span><h2>A Deep Neural Network with Concatenated Input Streams<a class="headerlink" href="#module-dnn_concat_model" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="dnn_concat_model.dnn_concat">
<code class="descclassname">dnn_concat_model.</code><code class="descname">dnn_concat</code><span class="sig-paren">(</span><em>data, configfile, layers=[16, 8], activation='tanhlecun', initrange=0.001, bn=True, keep_prob=0.95, concat_size=24, uembed=32, iembed=32, learnrate=1e-05, verbose=True, epochs=10, maxbadcount=20, mb=2000, eval_rate=500</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dnn_concat_model.html#dnn_concat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dnn_concat_model.dnn_concat" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<img alt="_images/dnn_concat.png" class="align-center" src="_images/dnn_concat.png" />
<div class="section" id="id6">
<h3>Sample Config<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span></span>out linear(1, True)
-h1 dnn([16, 8], activation=&#39;tanhlecun&#39;, bn=True, keep_prob=.95)
--x concat(24)
---huser lookup(dataname=&#39;user&#39;, initrange=.001, shape=[None, $embed])
---hitem lookup(dataname=&#39;item&#39;, initrange=.001, shape=[None, $embed])
</pre></div>
</div>
</div>
</div>
<div class="section" id="multiplicative-interaction-between-text-user-and-item">
<h2>Multiplicative Interaction between Text, User, and Item<a class="headerlink" href="#multiplicative-interaction-between-text-user-and-item" title="Permalink to this headline">¶</a></h2>
<img alt="_images/multoutputs.png" class="align-center" src="_images/multoutputs.png" />
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="tutorials.html" title="Tutorials"
             >next</a> |</li>
        <li class="right" >
          <a href="generic_model.html" title="generic_model"
             >previous</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>

          <li class="nav-item nav-item-1"><a href="api.html" >API: ANT modules</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2016, Aaron Tuor.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.6.
    </div>
  </body>
</html>